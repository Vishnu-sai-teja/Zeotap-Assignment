{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "customers_df = pd.read_csv('data/Customers.csv')\n",
    "products_df = pd.read_csv('data/Products.csv')\n",
    "transactions_df = pd.read_csv('data/Transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_product_customer_transaction_df = pd.merge(\n",
    "    pd.merge(transactions_df, customers_df, on='CustomerID', suffixes=('', '_transactions'), how='inner'),\n",
    "    products_df, on='ProductID', how='inner', suffixes=('','_products')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wn/6gtgtpjs45g6pvg35tcp8bzw0000gn/T/ipykernel_44751/4130172693.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  temp_customer_df = combined_product_customer_transaction_df.groupby('CustomerID').apply(lambda x : x)\n"
     ]
    }
   ],
   "source": [
    "temp_customer_df = combined_product_customer_transaction_df.groupby('CustomerID').apply(lambda x : x)\n",
    "temp_customer_df = temp_customer_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature processing - to better represent the data\n",
    "\n",
    "# Count the number of transactions per category for each customer\n",
    "category_counts = combined_product_customer_transaction_df.groupby(['CustomerID', 'Category']).size().unstack(fill_value=0)\n",
    "category_counts.columns = [f'Category_count_{col}' for col in category_counts.columns]\n",
    "category_counts = category_counts.reset_index()\n",
    "\n",
    "# Count the number of transactions per quantity for each customer\n",
    "quantity_counts = combined_product_customer_transaction_df.groupby(['CustomerID', 'Quantity']).size().unstack(fill_value=0)\n",
    "quantity_counts.columns = [f'Quantity_count_{col}' for col in quantity_counts.columns]\n",
    "quantity_counts = quantity_counts.reset_index()\n",
    "\n",
    "# Merge the category and quantity counts with the main dataframe\n",
    "merged_df = temp_customer_df.merge(category_counts, on=\"CustomerID\").merge(quantity_counts, on=\"CustomerID\")\n",
    "\n",
    "merged_df['spent_per_item'] = merged_df['Price'] / merged_df['Quantity']\n",
    "merged_df['average_spending_per_product'] = merged_df.groupby('CustomerID')['spent_per_item'].transform('mean')\n",
    "\n",
    "merged_df['total_quantity'] = merged_df.groupby('CustomerID')['Quantity'].transform('sum')\n",
    "merged_df['average_quantity'] = merged_df.groupby('CustomerID')['Quantity'].transform('mean')\n",
    "merged_df['total_value'] = merged_df.groupby('CustomerID')['TotalValue'].transform('sum')\n",
    "\n",
    "merged_df['SignupDate'] = pd.to_datetime(merged_df['SignupDate'])\n",
    "merged_df['TransactionDate'] = pd.to_datetime(merged_df['TransactionDate'])\n",
    "merged_df['Customer Since'] = (merged_df['TransactionDate'] - merged_df['SignupDate']).dt.days\n",
    "merged_df['Customer Since'] = merged_df.groupby('CustomerID')['Customer Since'].transform('mean')\n",
    "\n",
    "merged_df['TransactionDate'] = pd.to_datetime(merged_df['TransactionDate'])\n",
    "\n",
    "# Create columns for each quarter of 2024\n",
    "for quarter, (start_month, end_month) in enumerate([(1, 3), (4, 6), (7, 9), (10, 12)], start=1):\n",
    "    quarter_col = f'transaction_value_2024_q{quarter}'\n",
    "    merged_df[quarter_col] = merged_df.apply(\n",
    "        lambda row: row['TotalValue'] if row['TransactionDate'].year == 2024 and start_month <= row['TransactionDate'].month <= end_month else 0, axis=1\n",
    "    )\n",
    "\n",
    "# Sum the values for all customers for each quarter\n",
    "for quarter in range(1, 5):\n",
    "    quarter_col = f'transaction_value_2024_q{quarter}'\n",
    "    merged_df[quarter_col] = merged_df.groupby('CustomerID')[quarter_col].transform('sum')\n",
    "\n",
    "# Perform one-hot encoding for the 'region column using 0/1\n",
    "region_dummies = pd.get_dummies(merged_df['Region'], prefix='Region', drop_first=False, dtype=int)\n",
    "merged_df = pd.concat([merged_df, region_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['CustomerName', 'Price', 'ProductName', 'Category', 'Quantity', 'TransactionID', 'ProductID', 'TransactionDate', 'SignupDate', 'TotalValue', 'Price_products', 'spent_per_item', 'Region'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Drop unwanted cols and group the customer data \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmerged_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomerName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProductName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuantity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransactionID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProductID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransactionDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSignupDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotalValue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrice_products\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspent_per_item\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRegion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerID\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      4\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m~/Documents/ZeoTap Assignment /venv/lib/python3.10/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ZeoTap Assignment /venv/lib/python3.10/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Documents/ZeoTap Assignment /venv/lib/python3.10/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/ZeoTap Assignment /venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['CustomerName', 'Price', 'ProductName', 'Category', 'Quantity', 'TransactionID', 'ProductID', 'TransactionDate', 'SignupDate', 'TotalValue', 'Price_products', 'spent_per_item', 'Region'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Drop unwanted cols and group the customer data \n",
    "merged_df.drop(['CustomerName', 'Price', 'ProductName', 'Category', 'Quantity', 'TransactionID', 'ProductID', 'TransactionDate', 'SignupDate','TotalValue', 'Price_products','spent_per_item','Region'], axis=1, inplace=True)\n",
    "merged_df = merged_df.groupby('CustomerID').mean()\n",
    "merged_df = merged_df.reset_index()\n",
    "\n",
    "customer_ids = merged_df['CustomerID']\n",
    "merged_df = merged_df.drop('CustomerID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_values = scaler.fit_transform(merged_df)\n",
    "merged_df = pd.DataFrame(scaled_values, columns=merged_df.columns)\n",
    "\n",
    "class LookAlike:\n",
    "    def __init__(self, customer_data):\n",
    "        self.customer_data = customer_data\n",
    "\n",
    "    def cosine_similarity(self, vector_a, vector_b):\n",
    "        dot_product = np.dot(vector_a, vector_b)\n",
    "        norm_a = np.linalg.norm(vector_a)\n",
    "        norm_b = np.linalg.norm(vector_b)\n",
    "        if norm_a == 0 or norm_b == 0:\n",
    "            return 0.0\n",
    "        similarity = dot_product / (norm_a * norm_b)\n",
    "        return similarity\n",
    "\n",
    "    def get_top_three_similar_customers(self, customer_index):\n",
    "        target_vector = self.customer_data[customer_index]\n",
    "        similarity_scores = []\n",
    "\n",
    "        for idx, vector in enumerate(self.customer_data):\n",
    "            if idx != customer_index:\n",
    "                similarity = self.cosine_similarity(target_vector, vector)\n",
    "                similarity_scores.append((idx, similarity))\n",
    "\n",
    "        similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_three_with_scores = similarity_scores[:3]\n",
    "        return [idx for idx, _ in top_three_with_scores]\n",
    "\n",
    "\n",
    "customer_data = merged_df.values\n",
    "lookalike = LookAlike(customer_data)\n",
    "\n",
    "lookalike_map = {\n",
    "    customer_ids.iloc[customer_index]: [\n",
    "        (customer_ids.iloc[idx], round(lookalike.cosine_similarity(customer_data[customer_index], customer_data[idx]), 2))\n",
    "        for idx in lookalike.get_top_three_similar_customers(customer_index)\n",
    "    ]\n",
    "    for customer_index in range(min(20, len(customer_ids)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookalike_df = pd.DataFrame([\n",
    "    {'CustomerID': key, 'SimilarCustomers': [(cust_id, float(score)) for cust_id, score in value]}\n",
    "    for key, value in lookalike_map.items()\n",
    "])\n",
    "lookalike_df.to_csv('Lookalike.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C0001': [('C0120', np.float64(0.92)),\n",
       "  ('C0188', np.float64(0.91)),\n",
       "  ('C0174', np.float64(0.9))],\n",
       " 'C0002': [('C0106', np.float64(0.95)),\n",
       "  ('C0043', np.float64(0.94)),\n",
       "  ('C0040', np.float64(0.91))],\n",
       " 'C0003': [('C0129', np.float64(0.93)),\n",
       "  ('C0039', np.float64(0.92)),\n",
       "  ('C0163', np.float64(0.91))],\n",
       " 'C0004': [('C0113', np.float64(0.94)),\n",
       "  ('C0104', np.float64(0.93)),\n",
       "  ('C0168', np.float64(0.92))],\n",
       " 'C0005': [('C0007', np.float64(0.92)),\n",
       "  ('C0043', np.float64(0.91)),\n",
       "  ('C0186', np.float64(0.91))],\n",
       " 'C0006': [('C0011', np.float64(0.94)),\n",
       "  ('C0137', np.float64(0.92)),\n",
       "  ('C0187', np.float64(0.91))],\n",
       " 'C0007': [('C0140', np.float64(0.92)),\n",
       "  ('C0005', np.float64(0.92)),\n",
       "  ('C0040', np.float64(0.91))],\n",
       " 'C0008': [('C0098', np.float64(0.94)),\n",
       "  ('C0154', np.float64(0.89)),\n",
       "  ('C0049', np.float64(0.88))],\n",
       " 'C0009': [('C0119', np.float64(0.89)),\n",
       "  ('C0103', np.float64(0.86)),\n",
       "  ('C0198', np.float64(0.84))],\n",
       " 'C0010': [('C0062', np.float64(0.94)),\n",
       "  ('C0061', np.float64(0.91)),\n",
       "  ('C0132', np.float64(0.9))],\n",
       " 'C0011': [('C0168', np.float64(0.95)),\n",
       "  ('C0171', np.float64(0.94)),\n",
       "  ('C0006', np.float64(0.94))],\n",
       " 'C0012': [('C0104', np.float64(0.93)),\n",
       "  ('C0163', np.float64(0.92)),\n",
       "  ('C0004', np.float64(0.92))],\n",
       " 'C0013': [('C0102', np.float64(0.93)),\n",
       "  ('C0107', np.float64(0.93)),\n",
       "  ('C0188', np.float64(0.92))],\n",
       " 'C0014': [('C0063', np.float64(0.86)),\n",
       "  ('C0121', np.float64(0.85)),\n",
       "  ('C0089', np.float64(0.85))],\n",
       " 'C0015': [('C0058', np.float64(0.9)),\n",
       "  ('C0094', np.float64(0.87)),\n",
       "  ('C0042', np.float64(0.87))],\n",
       " 'C0016': [('C0042', np.float64(0.87)),\n",
       "  ('C0194', np.float64(0.86)),\n",
       "  ('C0156', np.float64(0.85))],\n",
       " 'C0017': [('C0075', np.float64(0.94)),\n",
       "  ('C0081', np.float64(0.93)),\n",
       "  ('C0057', np.float64(0.92))],\n",
       " 'C0018': [('C0117', np.float64(0.92)),\n",
       "  ('C0046', np.float64(0.89)),\n",
       "  ('C0059', np.float64(0.88))],\n",
       " 'C0019': [('C0121', np.float64(0.91)),\n",
       "  ('C0023', np.float64(0.91)),\n",
       "  ('C0070', np.float64(0.89))],\n",
       " 'C0020': [('C0036', np.float64(0.9)),\n",
       "  ('C0033', np.float64(0.88)),\n",
       "  ('C0185', np.float64(0.87))]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookalike_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
